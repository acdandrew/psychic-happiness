{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of Attack\n",
    "1. Create sample out of imdb data set\n",
    "    * Preprocess for rare words (done [handled by load_data])\n",
    "    * Pad all entries to 500 words (done [keras.preprocessing])\n",
    "    * Simple randomly select 10% (done [random.shuffle zip trick])\n",
    "    * Use bcolz to save off what we did (light weight data so not doing)\n",
    "2. Create simple simple model to exercise functional api and verify stuff works\n",
    "    * Grok the embedding and create simple functional layer of 1D convolution (done)\n",
    "3. Bring in pretrained model and verify that we get similar performance\n",
    "4. Attempt to beat jeremy's score (.90 val ac)\n",
    "    * Can we preprocess words similar to how glove did it?\n",
    "    * Deeper network\n",
    "    * Number of words as a side channel using functional api?\n",
    "    * 2d convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,random, shutil\n",
    "import numpy as np\n",
    "#vgg is held in a subdirectory\n",
    "sys.path.append('kernel')\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "import keras as k\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Convolution1D\n",
    "from keras.layers import Convolution2D, MaxPooling2D,Flatten,Dropout\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.preprocessing import image,sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "#import bcolz\n",
    "import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample out of IMDB data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x_train = sequence.pad_sequences(x_train, maxlen=500)\n",
    "padded_x_test = sequence.pad_sequences(x_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = zip(padded_x_train, y_train)\n",
    "random.shuffle(c)\n",
    "x_train, y_train = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(x_train)\n",
    "y_train = list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[-2500:]\n",
    "y_val = y_train[-2500:]\n",
    "x_train = x_train[:len(x_train)-2500]\n",
    "y_train = y_train[:len(y_train)-2500]\n",
    "x_t = np.asarray(x_train)\n",
    "y_t = np.asarray(y_train)\n",
    "x_v = np.asarray(x_val)\n",
    "y_v = np.asarray(y_val)\n",
    "x_test = np.asarray(padded_x_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with an embedding layer with 32 random weights\n",
    "main_input = Input(shape=(500,), dtype='int32' ,name='main_input')\n",
    "\n",
    "embedding = Embedding(input_dim=5000, output_dim=32,input_length=500)(main_input)\n",
    "c = Convolution1D(64, 5)(embedding)\n",
    "f = Flatten()(c)\n",
    "d = Dense(500, activation='relu')(f)\n",
    "d = Dropout(.1)(d)\n",
    "d = Dense(250, activation='relu')(d)\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(d)\n",
    "model = Model(inputs=[main_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 496, 64)           10304     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 31744)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               15872500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 16,168,305\n",
      "Trainable params: 16,168,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/1\n",
      "22500/22500 [==============================] - 538s - loss: 0.2249 - acc: 0.9097 - val_loss: 0.2986 - val_acc: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9a9ed8e10>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_t,y_t, batch_size=32, epochs=1, validation_data=(x_v,y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 500)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 121s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29590418436050414, 0.87612000000000001]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreTrained Model using Glove Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
